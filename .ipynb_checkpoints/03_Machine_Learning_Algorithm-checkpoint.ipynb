{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/vinay_dara/Desktop/HK6/MothersDay/Data/output/output_prepared_stacked.csv')\n",
    "df['piece_item_desc'] = df['piece_item_desc'].astype(str)\n",
    "df['COMMODITY_EXTRACT'] = df['piece_item_desc']\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#cleaning the text data\n",
    "def pre_process(COMMODITY_EXTRACT):\n",
    "    \n",
    "    # lowercase\n",
    "    COMMODITY_EXTRACT=COMMODITY_EXTRACT.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    COMMODITY_EXTRACT=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",COMMODITY_EXTRACT)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    COMMODITY_EXTRACT=re.sub(\"(\\\\d|\\\\W)+\",\" \",COMMODITY_EXTRACT)\n",
    "    \n",
    "    return COMMODITY_EXTRACT\n",
    "\n",
    "df['COMMODITY_EXTRACT'] = df['COMMODITY_EXTRACT'].apply(lambda x:pre_process(x))\n",
    "\n",
    "#Hiding unwanted columns from the dataframe\n",
    "df['COMMODITY_DESC'] = df['COMMODITY_DESC'].astype(str)\n",
    "from io import StringIO\n",
    "col = ['COMMODITY_DESC', 'COMMODITY_EXTRACT']\n",
    "df = df[col]\n",
    "df.columns = ['COMMODITY_DESC', 'COMMODITY_EXTRACT']\n",
    "df['category_id'] = df['COMMODITY_DESC'].factorize()[0]\n",
    "category_id_df = df[['COMMODITY_DESC', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'COMMODITY_DESC']].values)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe9d24817b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 26})\n",
    "fig = plt.figure(figsize=(40,20))\n",
    "df.groupby('COMMODITY_DESC').COMMODITY_EXTRACT.count().plot.bar(ylim=0)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial', 'artificial foliage', 'birds', 'birds paradise', 'bouquet', 'bulb', 'bulbs', 'consolidated', 'consolidation', 'cur', 'cur flowers', 'cut', 'cut flower', 'cut flowers', 'cut fresh', 'cutflower', 'cutflowers', 'fersh', 'fersh cut', 'fesh', 'fesh cut', 'flower', 'flower bulb', 'flower bulbs', 'flowers', 'flowers bulbs', 'flowers foliage', 'flowers foliages', 'flowers fruit', 'flowers nhz', 'flowers nohz', 'flowers non', 'flowers roses', 'flowers sl', 'foliage', 'foliages', 'freash', 'freash cut', 'frech', 'frech cut', 'freh', 'freh cut', 'frehs', 'frehs cut', 'fresch', 'fresch cut', 'fresg', 'fresg cut', 'fresh', 'fresh cur', 'fresh cut', 'fresh cutflower', 'fresh cutflowers', 'fresh flower', 'fresh flowers', 'fresh foliage', 'fresh lilies', 'fresh loroco', 'fresh roses', 'fresh tropical', 'fresh tulips', 'freshcut', 'freshcut flowers', 'frsh', 'frsh cut', 'fruit', 'gipsophilia', 'gipsophilia leather', 'gipsphilia', 'gipsphilia leather', 'gypsophila', 'leaf', 'leather', 'leather leaf', 'lilies', 'lily', 'loroco', 'nhz', 'nohz', 'non', 'orchids', 'ornamental', 'paper', 'paradise', 'perishable', 'pla', 'preserved', 'preserved flowers', 'resh', 'resh cut', 'roses', 'roses gipsophilia', 'roses gipsphilia', 'roses gypsophila', 'roses leather', 'ruscus', 'sl', 'stb', 'stb lily', 'supplies', 'tropical', 'tropical flowers', 'tropical foliage', 'tulips']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(29862, 104)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text Representation - Learning from text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(['xx','xl','ttl','tro','stc','spx','slc','sla','slacs',\"per\",\"slac\",\"xxx\",'pre','xxxx','att','nodg','nhaz','gen','haz','ice','aog','rmd','lho','val','hum','dip','bag','vic','shl','mrx','dgr','act','fro','crt','col','ert','mal','cat','pil','med','avi','vic','tcs','dgr',\"xxx\",'bxs','ecc','ecp','slac','ndg','ake','salc','aa','ewp','skd', 'kg', 'avi', 'per', 'dgs', 'eap','eat','eaw','er','exx','fcf'])\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=False, analyzer='word', min_df=5, norm='l2', encoding='utf-8', ngram_range=(1, 2), stop_words=my_stop_words)\n",
    "features = tfidf.fit_transform(df.COMMODITY_EXTRACT).toarray()\n",
    "labels = df.category_id\n",
    "tf_feature_names = tfidf.get_feature_names()\n",
    "\n",
    "print(tf_feature_names)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'CUT FLOWERS FOLIAGE CUTTIN':\n",
      "  . Most correlated unigrams:\n",
      ". lilies\n",
      ". tulips\n",
      "  . Most correlated bigrams:\n",
      ". fresh roses\n",
      ". fresh loroco\n",
      "# 'LILLIES':\n",
      "  . Most correlated unigrams:\n",
      ". lily\n",
      ". lilies\n",
      "  . Most correlated bigrams:\n",
      ". stb lily\n",
      ". fresh lilies\n",
      "# 'LOROCO':\n",
      "  . Most correlated unigrams:\n",
      ". fesh\n",
      ". loroco\n",
      "  . Most correlated bigrams:\n",
      ". cut flowers\n",
      ". fresh loroco\n",
      "# 'ROSES':\n",
      "  . Most correlated unigrams:\n",
      ". leather\n",
      ". roses\n",
      "  . Most correlated bigrams:\n",
      ". roses gipsphilia\n",
      ". fresh roses\n",
      "# 'TULIPS':\n",
      "  . Most correlated unigrams:\n",
      ". flowers\n",
      ". tulips\n",
      "  . Most correlated bigrams:\n",
      ". cut flowers\n",
      ". fresh tulips\n"
     ]
    }
   ],
   "source": [
    "#Understanding correlation\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 2\n",
    "for COMMODITY_DESC, category_id in sorted(category_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == category_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tf_feature_names)[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  print(\"# '{}':\".format(COMMODITY_DESC))\n",
    "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the classifier - machine learning Naive Bayes Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['COMMODITY_EXTRACT'], df['COMMODITY_DESC'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('/home/vinay_dara/Desktop/HK6/MothersDay/Data/input/no_commodity_codes_2017_2018.csv')\n",
    "df_results['PIECE_ITEM_DESC'] = df_results['PIECE_ITEM_DESC'].astype(str)\n",
    "df_results['PREDICTED_COMMODITY'] = 'DEBUG'\n",
    "\n",
    "for index,row in df_results.iterrows():\n",
    "    df_results.loc[index,'PREDICTED_COMMODITY'] = clf.predict(count_vect.transform([row['PIECE_ITEM_DESC']]))\n",
    "\n",
    "#df_results['PREDICTED_COMMODITY'] = df_results['PREDICTED_COMMODITY'].astype(str)\n",
    "df_results.to_csv('/home/vinay_dara/Desktop/HK6/MothersDay/Data/input/ML_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
